# ğŸ¤ AI Voice Agent â€“ #30DaysOfVoiceAgents Challenge

An **end-to-end AI-powered conversational voice bot** built with **FastAPI**, **AssemblyAI**, **Murf AI**, and **Google Gemini**.

This bot can:
- ğŸ™ Listen to your voice
- ğŸ“ Transcribe speech to text
- ğŸ¤– Understand context using an LLM
- ğŸ”Š Reply in natural-sounding speech
- ğŸ’¬ Maintain conversation history

---

## ğŸ“… Journey: Day 1 â€“ Day 13

| Day | Task | Key Outcome |
|-----|------|-------------|
| 1ï¸âƒ£ | Project Setup | FastAPI + HTML/JS frontend |
| 2ï¸âƒ£ | REST TTS API | Murf text-to-speech endpoint |
| 3ï¸âƒ£ | Play TTS Audio | UI to play generated speech |
| 4ï¸âƒ£ | Echo Bot v1 | Record & replay user voice |
| 5ï¸âƒ£ | Send Audio to Server | Upload & save recordings |
| 6ï¸âƒ£ | Server Transcription | AssemblyAI transcription |
| 7ï¸âƒ£ | Echo Bot v2 | Murf voice for echo |
| 8ï¸âƒ£ | LLM Integration | Google Gemini API |
| 9ï¸âƒ£ | Full Pipeline | Voice â†’ LLM â†’ Voice |
| ğŸ”Ÿ | Chat History | Session-based memory |
| 1ï¸âƒ£1ï¸âƒ£ | Error Handling | Client & server resilience |
| 1ï¸âƒ£2ï¸âƒ£ | UI Revamp | Conversational UI & dynamic button |
| 1ï¸âƒ£3ï¸âƒ£ | Documentation | README + setup guide |
| 1ï¸âƒ£4ï¸âƒ£ |Refactor Code & GitHub |




---

## ğŸ›  Technologies
- **Backend**: FastAPI (Python)
- **Frontend**: HTML, CSS, JavaScript
- **STT**: [AssemblyAI](https://www.assemblyai.com/)
- **TTS**: [Murf AI](https://murf.ai/)
- **LLM**: [Google Gemini](https://ai.google.dev/)
- **Browser API**: MediaRecorder API

---

## ğŸ— Architecture Diagram

```plaintext
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   User Voice  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚ ğŸ™
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STT (AssemblyAI)   â”‚
â”‚ Speech â†’ Text      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚ ğŸ“
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LLM (Google Gemini)â”‚
â”‚ Understand Context â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚ ğŸ’¡
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ TTS (Murf AI)      â”‚
â”‚ Text â†’ Speech      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚ ğŸ”Š
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Voice Response     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ’¬ Conversation history stored per session


âœ¨ Features

ğŸ¤ Record voice directly in the browser

ğŸ“ Accurate transcription with AssemblyAI

ğŸ¤– Context-aware LLM responses

ğŸ”Š Realistic Murf voice output

ğŸ’¬ Persistent chat history

âš  Error handling & fallback responses


==============================================================================================================================================================================

 File Structure
Ensure your project directory is organized as follows:

/my_project/
â”œâ”€â”€ main.py
â”œâ”€â”€ .env
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ /static/
â”‚   â””â”€â”€ script.js
â”œâ”€â”€ /templates/
â”‚   â””â”€â”€ index.html


==========================================================================================================================================================================

4.2. Install Dependencies
Activate your Python virtual environment and install the required packages:

Bash

pip install -r requirements.txt
The requirements.txt file should contain:

fastapi
uvicorn
python-dotenv
requests
assemblyai
google-generativeai
4.3. Set Environment Variables
Create and fill in your API keys in the .env file:

Code snippet

MURF_API_KEY="your_murf_api_key_here"
ASSEMBLYAI_API_KEY="your_assemblyai_api_key_here"
GEMINI_API_KEY="your_gemini_api_key_here"
4.4. Start the Server
From the project root directory, run the following command:

Bash

uvicorn main:app --reload
The application will be accessible at http://127.0.0.1:8000.