ğŸ¤ AI Voice Agent â€“ #30DaysOfVoiceAgents Challenge

An end-to-end AI-powered conversational voice bot built with FastAPI, AssemblyAI, Murf AI, and Google Gemini.

This bot can:

ğŸ™ Listen to your voice

ğŸ“ Transcribe speech to text

ğŸ¤– Understand context using an LLM

ğŸ”Š Reply in natural-sounding speech

ğŸ’¬ Maintain conversation history

ğŸ“… Journey: Day 1 â€“ Day 16
Day	Task	Key Outcome
1ï¸âƒ£	Project Setup	FastAPI backend + HTML/JS frontend
2ï¸âƒ£	REST TTS API	Murf text-to-speech endpoint working
3ï¸âƒ£	Play TTS Audio	UI to send text â†’ get speech playback
4ï¸âƒ£	Echo Bot v1	Record & replay user voice (MediaRecorder API)
5ï¸âƒ£	Send Audio to Server	Upload recorded audio to FastAPI
6ï¸âƒ£	Server Transcription	AssemblyAI speech-to-text integration
7ï¸âƒ£	Echo Bot v2	Murf AI speaks back what you said
8ï¸âƒ£	LLM Integration	Google Gemini API connected
9ï¸âƒ£	Full Pipeline	Voice â†’ STT â†’ LLM â†’ TTS â†’ Voice
ğŸ”Ÿ	Chat History	Session-based memory enabled
1ï¸âƒ£1ï¸âƒ£	Error Handling	Robust server & client fallbacks
1ï¸âƒ£2ï¸âƒ£	UI Revamp	Clean conversational UI & animated record button
1ï¸âƒ£3ï¸âƒ£	Documentation	Initial README & setup guide
1ï¸âƒ£4ï¸âƒ£	Refactor + GitHub	Services folder + schemas + logging
1ï¸âƒ£5ï¸âƒ£	WebSockets	Client-server messaging with /ws
1ï¸âƒ£6ï¸âƒ£	Streaming Audio	Real-time audio sent & saved via WebSocket
1ï¸âƒ£7ï¸âƒ£   WebSocket in UI HTML/JS frontend connects to /ws and exchanges live messages



ğŸ›  Technologies

Backend: FastAPI (Python)

Frontend: HTML, CSS, JavaScript

STT: AssemblyAI

TTS: Murf AI

LLM: Google Gemini

Browser API: MediaRecorder API, WebSockets

ğŸ— Architecture Diagram
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   User Voice  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚ ğŸ™
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STT (AssemblyAI)   â”‚
â”‚ Speech â†’ Text      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚ ğŸ“
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LLM (Google Gemini)â”‚
â”‚ Understand Context â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚ ğŸ’¡
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ TTS (Murf AI)      â”‚
â”‚ Text â†’ Speech      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚ ğŸ”Š
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Voice Response     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ’¬ Conversation history stored per session

âœ¨ Features (till Day 16)

ğŸ¤ Record voice directly in the browser

ğŸ“ Accurate transcription with AssemblyAI

ğŸ¤– Context-aware LLM responses

ğŸ”Š Realistic Murf voice output

ğŸ’¬ Persistent chat history

âš¡ WebSocket-based streaming pipeline

ğŸ›¡ Error handling & resilience

ğŸ“‚ File Structure
/voice-agent/
â”œâ”€â”€ app.py                # FastAPI entrypoint
â”œâ”€â”€ .env                  # API keys
â”œâ”€â”€ requirements.txt      
â”œâ”€â”€ /services/            # STT, TTS, LLM integrations
â”œâ”€â”€ /static/              # JS, CSS
â”‚   â””â”€â”€ script.js
â”œâ”€â”€ /templates/           
â”‚   â””â”€â”€ index.html
â”œâ”€â”€ /uploads/             # Temp audio files

âš™ï¸ Setup & Run

1ï¸âƒ£ Clone repo & install deps:

pip install -r requirements.txt


2ï¸âƒ£ Add .env file:

MURF_API_KEY=your_murf_key
ASSEMBLYAI_API_KEY=your_assemblyai_key
GEMINI_API_KEY=your_gemini_key


3ï¸âƒ£ Run server:

uvicorn app:app --reload


4ï¸âƒ£ Open browser at:
ğŸ‘‰ http://127.0.0.1:8000